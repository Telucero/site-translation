==============================
Advanced n8n Translation Flow
==============================

This guide describes an opinionated n8n workflow that receives GitHub documentation updates, translates them responsibly, runs verification/formatting, and ships the localized Markdown back to GitHub. Place this workflow alongside the existing basic example; it assumes payloads like the ones sent by `.github/workflows/translate.yml`. The concrete example below mirrors the webhook test payload captured from production.

-------------------------------------------------
1. High-Level Node Graph (in execution order)
-------------------------------------------------

1. Webhook (Trigger)
2. Function: `validatePayload`
3. IF: `translationRequired` (optional early exit)
4. Function: `filterFiles` (enforce allow/deny lists)
5. Function: `prepareJobs`
6. Code: `langCode` (normalize locale casing)
7. DeepL Node: `Translate a language`
8. Code: `postProcessing` (provider response normalizer)
9. Code: `verifyContent`
10. IF: `hasVerificationErrors`
11. Code: `formatMarkdown`
12. Function: `prepareGitHubPayload`
13. HTTP Request(s): GitHub SHA lookup + commit (optional)
14. Function: `collectTranslations`
15. Respond to Webhook
16. (Optional) Error Handling path → Slack / Email

Each node is detailed below.

--------------------------------------------
2. Webhook Node Configuration
--------------------------------------------

- Method: `POST`
- Path: `/docs/translate`
- Respond: `When Last Node Finishes`
- Auth: Token header (`X-Workflow-Token`). In production, the GitHub Action sends a bearer-style secret; fall back to IP allow lists if desired.

Incoming payload (abridged example from webhook test):

```
{
  "headers": {
    "content-type": "application/json",
    "user-agent": "python-requests/2.31.0",
    "x-forwarded-for": "172.215.209.72",
    "...": "..."
  },
  "body": {
    "branch": "refs/heads/main",
    "commit": "761456cb386c2fb40bfeec545f70607ac65ae408",
    "default_language": "en",
    "target_languages": ["es", "fr"],
    "documents": [
      {
        "path": "docs/en/index.md",
        "language": "en",
        "checksum": "3b06c74...",
        "content": "# Documentation Demo\\n..."
      },
      {
        "path": "docs/en/reference/api.md",
        "language": "en",
        "checksum": "bafca867...",
        "content": "# API Overview\\n..."
      }
    ]
  }
}
```

The workflow should consistently reference `items[0].json.body` for business data and may inspect `items[0].json.headers` for additional context (IP filtering, debug logs, etc.).

------------------------------------------------------
3. Function Node — `validatePayload`
------------------------------------------------------

Purpose: Guard against malformed requests before expensive translation calls.

JavaScript:

```javascript
const docSchema = ["path", "language", "checksum", "content"];
const errors = [];
const payload = items[0].json.body || {};

if (!Array.isArray(payload.documents) || payload.documents.length === 0) {
  errors.push("Missing documents array");
}

if (!Array.isArray(payload.target_languages) || payload.target_languages.length === 0) {
  errors.push("Missing target_languages");
}

if (!payload.branch || !payload.commit) {
  errors.push("Branch and commit metadata are required");
}

if (payload.documents) {
  for (const doc of payload.documents) {
    for (const key of docSchema) {
      if (!doc[key]) {
        errors.push(`Document ${doc.path ?? "<unknown>"} missing key: ${key}`);
      }
    }
    if (!doc.path.startsWith("docs/en/")) {
      errors.push(`Document outside allowed scope: ${doc.path}`);
    }
  }
}

if (errors.length) {
  throw new Error(`Payload validation failed: ${errors.join("; ")}`);
}

return items;
```

------------------------------------------------------
4. IF Node — `translationRequired`
------------------------------------------------------

- Expression: `{{ ($json.body?.documents?.length ?? 0) > 0 && ($json.body?.target_languages?.length ?? 0) > 0 }}`
- If false → `Respond to Webhook` with `{ "translations": [] }`.

------------------------------------------------------
5. Function Node — `filterFiles`
------------------------------------------------------

Purpose: Skip files that should never be machine-translated (e.g., legal pages, changelog, specific filenames).

Environment variables:
- `TRANSLATION_DENYLIST` (comma-separated glob patterns)
- `TRANSLATION_ALLOWLIST` (optional, comma-separated patterns)

JavaScript:

```javascript
const payload = items[0].json.body || {};
const { documents = [] } = payload;
const deny = (process.env.TRANSLATION_DENYLIST || "")
  .split(",")
  .map((p) => p.trim())
  .filter(Boolean);
const allow = (process.env.TRANSLATION_ALLOWLIST || "")
  .split(",")
  .map((p) => p.trim())
  .filter(Boolean);

const micromatch = require("micromatch");

const filtered = documents.filter((doc) => {
  if (allow.length && !micromatch.isMatch(doc.path, allow)) {
    return false;
  }
  if (deny.length && micromatch.isMatch(doc.path, deny)) {
    return false;
  }
  return true;
});

if (!filtered.length) {
  throw new Error("No documents left after filter; aborting translation.");
}

return [
  {
    json: {
      ...items[0].json,
      body: {
        ...payload,
        documents: filtered
      }
    }
  }
];
```

Install `micromatch` in n8n if not already available.

------------------------------------------------------
6. Function Node — `prepareJobs`
------------------------------------------------------

Same logic as earlier, but we add metadata for downstream verification.

JavaScript:

```javascript
const payload = items[0].json.body;
const jobs = [];

for (const doc of payload.documents) {
  for (const locale of payload.target_languages) {
    jobs.push({
      json: {
        source_path: doc.path,
        source_language: payload.default_language,
        target_language: locale,
        checksum: doc.checksum,
        content: doc.content,
        branch: payload.branch,
        commit: payload.commit
      }
    });
  }
}

return jobs;
```

n8n automatically executes downstream nodes once per item, so batching is optional. After job preparation we uppercase locale codes for the provider and then call DeepL, followed by normalization and QA nodes.

------------------------------------------------------
6. Code Node — `langCode`
------------------------------------------------------

```javascript
// n8n Code node — capitalize language codes
const inputItems = $input.all();

function toUpperLang(code) {
  if (typeof code !== 'string') return code;
  return code.trim().toUpperCase();
}

return inputItems.map((item) => {
  const json = { ...(item.json || {}) };

  if (json.source_language != null) {
    json.source_language = toUpperLang(json.source_language);
  }
  if (json.target_language != null) {
    json.target_language = toUpperLang(json.target_language);
  }

  return { json };
});
```

------------------------------------------------------
7. DeepL Node — `Translate a language`
------------------------------------------------------

- Operation: *Translate Text*
- **Text**: `={{ $json.content }}`
- **Translate To**: `={{ $json.target_language }}`
- Additional fields: set `preserveFormatting = 0` and `formality = default` (tune per locale).
- Credentials: use your DeepL API credential in n8n.

If you need throttling, place a Wait/Split node before DeepL; otherwise each job flows through this node individually.

------------------------------------------------------
8. Code Node — `postProcessing`
------------------------------------------------------

Purpose: merge the DeepL response with the original job metadata, normalize whitespace, and keep both the English source (`content`) and translation (`translated_markdown`) for downstream QA.

```javascript
// n8n Code node — translation normalizer (content next to translated_markdown)
const inputItems = $input.all();
const langItems = $('langCode').all(); // upstream node with capitalized language codes + source fields

function getSourceIndex(item, fallbackIndex) {
  const p = item?.pairedItem;
  return (p && Number.isInteger(p.item)) ? p.item : fallbackIndex;
}

return inputItems.map((item, index) => {
  const sourceIndex = getSourceIndex(item, index);

  const langJson = langItems[sourceIndex]?.json ?? {};
  const payload = item.json;

  let detected = null;
  let translationText = "";

  if (Array.isArray(payload)) {
    const first = payload[0] ?? {};
    translationText =
      first.text ??
      first.translated_markdown ??
      first.output_text ??
      first.content ??
      (Array.isArray(first.data) ? first.data[0]?.text : "") ??
      "";
    detected =
      first.detected_source_language ??
      (Array.isArray(first.data) ? first.data[0]?.detected_source_language : null) ??
      null;
  } else {
    translationText =
      payload?.text
      ?? payload?.translated_markdown
      ?? payload?.output_text
      ?? payload?.content
      ?? (Array.isArray(payload?.data) ? payload.data[0]?.text : "")
      ?? payload?.body?.translated_markdown
      ?? payload?.body?.text
      ?? "";
    detected =
      payload?.detected_source_language
      ?? (Array.isArray(payload?.data) ? payload.data[0]?.detected_source_language : null)
      ?? payload?.body?.detected_source_language
      ?? null;
  }

  if (!translationText) {
    throw new Error("Translation provider response missing text field (looked for text/translated_markdown/output_text/content).");
  }

  const normalized = String(translationText)
    .replace(/\u00a0/g, " ")
    .replace(/
/g, "
")
    .trimEnd() + "\n";

  const { content, ...rest } = langJson;

  const out = {
    ...rest,
    content: String(content ?? ""),
    translated_markdown: normalized,
  };

  if (detected) {
    out.provider_metadata = { detected_source_language: detected };
  }

  return { json: out };
});
```

------------------------------------------------------
9. Code Node — `verifyContent`
------------------------------------------------------

```javascript
// n8n Code node — translation QA checks (aligned with previous normalizer)
const inputItems = $input.all();

const PLACEHOLDER_REGEX = /{{\s*[\w.-]+\s*}}/g;

function sameMultiset(a = [], b = []) {
  const count = (arr) => {
    const m = new Map();
    for (const x of arr) m.set(x, (m.get(x) || 0) + 1);
    return m;
  };
  const ma = count(a);
  const mb = count(b);
  if (ma.size !== mb.size) return false;
  for (const [k, va] of ma) if (mb.get(k) != va) return false;
  return true;
}

return inputItems.map((item, idx) => {
  const json = item.json || {};

  const original = typeof json.content === "string" ? json.content : "";
  const translated = typeof json.translated_markdown === "string" ? json.translated_markdown : "";

  const errs = [];

  if (!original) {
    errs.push(`Missing English source content for ${json.source_path || "(unknown path)"} (${json.source_language || "?"}).`);
  }
  if (!translated) {
    errs.push(`Missing translated_markdown for ${json.source_path || "(unknown path)"} (${json.target_language || "?"}).`);
  }

  if (original && translated) {
    const srcPlaceholders = original.match(PLACEHOLDER_REGEX) || [];
    const dstPlaceholders = translated.match(PLACEHOLDER_REGEX) || [];
    if (!sameMultiset(srcPlaceholders, dstPlaceholders)) {
      errs.push(`Placeholder mismatch for ${json.source_path || "(unknown path)"} (${json.target_language || "?"}).`);
    }

    const srcFenceCount = (original.match(/```/g) || []).length;
    const dstFenceCount = (translated.match(/```/g) || []).length;

    if (srcFenceCount !== dstFenceCount) {
      errs.push(`Code fence count mismatch for ${json.source_path || "(unknown path)"} (${json.target_language || "?"}).`);
    }
    if (dstFenceCount % 2 !== 0) {
      errs.push(`Unclosed code fence detected in translation for ${json.source_path || "(unknown path)"} (${json.target_language || "?"}).`);
    }

    const ratio = translated.length / Math.max(1, original.length);
    if (ratio < 0.5 || ratio > 2.0) {
      errs.push(`Length ratio out of bounds for ${json.source_path || "(unknown path)"} (${json.target_language || "?"}) -> ${ratio.toFixed(2)}`);
    }
  }

  if (errs.length) {
    json.verification_errors = errs;
  } else {
    delete json.verification_errors;
  }

  return { json };
});
```

Follow up with an IF node configured as follows:

- **Mode**: `Expression`
- **Expression**: `={{ Array.isArray($json.verification_errors) && $json.verification_errors.length > 0 }}`
- This uses the `boolean` outcome of the expression. When it evaluates to `true`, route the item to the alert path (e.g., Slack/Email + Fail Execution). The `false` branch continues to formatting.

------------------------------------------------------
11. Function — `formatMarkdown`
------------------------------------------------------

Purpose: Apply deterministic Markdown formatting (e.g., ensure spacing around headings/lists). For complex needs, integrate a formatter container; here we keep lightweight adjustments.

JavaScript:

```javascript
function normalizeLists(markdown) {
  return markdown.replace(/(-|\*) {3,}/g, "$1 ");
}

function ensureHeadingSpacing(markdown) {
  return markdown.replace(/(#+ [^\n]+)(?!\n\n)/g, "$1\n");
}

return items.map((item) => {
  let md = item.json.translated_markdown;
  md = normalizeLists(md);
  md = ensureHeadingSpacing(md);

  item.json.translated_markdown = md;
  return item;
});
```

------------------------------------------------------
12. Merge Node
------------------------------------------------------

Collect all batches back into a single array. Configure the Merge node with:
- Mode: `Wait`
- Property: default

------------------------------------------------------
13. Ship Translations Back to GitHub
------------------------------------------------------

You can handle persistence in two ways:

**Option A — Respond only (recommended when you cannot store GitHub tokens in n8n)**

- Skip the GitHub HTTP Request nodes entirely.
- Keep `collectTranslations` and `Respond Success` so the webhook returns
  ```
  { "translations": [ { "language": "...", "path": "...", "content": "..." } ] }
  ```
- The GitHub Action writes files and commits using the built-in `GITHUB_TOKEN`
  (no PAT required, respects branch protection). This keeps credentials confined
  to GitHub and satisfies policies that disallow external storage of API keys.
- The helper script `scripts/request_translation.py` validates each translation
  entry (`path`, `content`) before writing to disk, ensuring the Action only
  commits well-formed updates.

**Option B — Commit from n8n (requires GitHub credential)**

- Retain the `getCurrentFileSHA` and `commitToGitHub` nodes, authenticating with
  a GitHub App or scoped machine account token stored in n8n.
- Only use this path if automation requirements mandate that n8n owns the
  commit. Guard with checksum comparisons and retries, and consider a dry-run
  mode.

Select the option that matches your security posture. If in doubt, use Option A
and let the Action perform the write-back with `GITHUB_TOKEN`.

------------------------------------------------------
14. Respond to Webhook
------------------------------------------------------

Return JSON back to GitHub Action:

```
{
  "translations": [
    {
      "language": "es",
      "path": "docs/es/index.md",
      "content": "...localized markdown..."
    }
  ],
  "verification_errors": []
}
```

If errors occurred, respond with `{ "error": "..." }` and HTTP 500 to force the Action to halt.

------------------------------------------------------
15. Error Handling
------------------------------------------------------

Attach the workflow to an “Error Workflow” or use the built-in `Execute Workflow On Error`. Recommended actions:
- Send Slack/Email notification with payload snapshot, job ID, and error message.
- Log failing documents to a persistent store (S3, database) for follow-up.
- Optionally requeue the translation request (retry with delay) while preventing infinite loops.

------------------------------------------------------
16. Additional Guardrails & Tips
------------------------------------------------------

- **Rate limiting**: Introduce a Wait node between batches if your provider has strict per-minute limits.
- **Language fallback**: If translation fails for a locale, respond with the original English content to avoid missing pages; flag the incident for manual review.
- **Glossary management**: If you host glossaries externally, add a node before `prepareJobs` to fetch the latest glossary terms and inject them into each translation request.
- **Formatting edge cases**: Consider a final `Code` node that rewrites relative links (e.g., replace `/en/` with `/es/`) if the translation service modifies them.
- **Unit testing**: Store example payloads (fixtures) and create an n8n manual trigger that feeds them into the workflow for repeatable testing without hitting GitHub.
- **Rollback strategy**: Provide a manual workflow that can revert the last localized commit in GitHub if QA discovers issues after publication.

------------------------------------------------------
17. Files & Variables Recap
------------------------------------------------------

Environment variables referenced:
- `TRANSLATION_DENYLIST` — Patterns to skip (e.g., `docs/en/legal/**,docs/en/changelog.md`).
- `TRANSLATION_ALLOWLIST` — Optional positive filter.
- `TRANSLATION_PROMPT` — System prompt for LLM providers.

Credentials:
- Translation API key (HTTP Request node credential).
- GitHub personal access token (repo scope).
- Slack/Email credentials for notifications.

Artifacts produced:
- Localized Markdown string per document.
- Optional verification log (array of warnings).
- Git commit or direct file updates in the target repository.

This setup balances automation with necessary oversight to keep multilingual documentation reliable. Adapt batch sizes, guardrails, and verification heuristics to match your translation provider and team workflow. 
